{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0888aAk4NB4m7WnWz2Y7V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annisaeka123/2341720131_ML_2025/blob/main/JS13/TP_JS13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas Praktikum"
      ],
      "metadata": {
        "id": "agl2ydsWkdPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan JST untuk klasifikasi angka tulisan tangan (MNIST).\n",
        "\n",
        "Langkah:\n",
        "\n",
        "- Load dataset MNIST dari Keras.\n",
        "\n",
        "- Bangun model dengan 2 hidden layer.\n",
        "\n",
        "- Latih model dan evaluasi akurasi."
      ],
      "metadata": {
        "id": "6OXQxlqlkfFK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tOTklrVkaOx",
        "outputId": "e8ec8760-7189-4512-b656-be6b607c545d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.4558 - val_accuracy: 0.9650 - val_loss: 0.1217\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9662 - loss: 0.1094 - val_accuracy: 0.9735 - val_loss: 0.0925\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0699 - val_accuracy: 0.9735 - val_loss: 0.0883\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0515 - val_accuracy: 0.9752 - val_loss: 0.0850\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0384 - val_accuracy: 0.9753 - val_loss: 0.0855\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0313 - val_accuracy: 0.9797 - val_loss: 0.0713\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0231 - val_accuracy: 0.9790 - val_loss: 0.0750\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0206 - val_accuracy: 0.9768 - val_loss: 0.0943\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0196 - val_accuracy: 0.9800 - val_loss: 0.0820\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0164 - val_accuracy: 0.9792 - val_loss: 0.0944\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.1087\n",
            "Akurasi pada data uji: 0.9786\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),       # Ubah 28x28 → vektor 784\n",
        "    Dense(128, activation='relu'),       # Hidden layer 1\n",
        "    Dense(64, activation='relu'),        # Hidden layer 2\n",
        "    Dense(10, activation='softmax')      # Output 10 kelas\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden Layer Lebih Besar (256 → 128)"
      ],
      "metadata": {
        "id": "eX5WubOzlqks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0sFMXkYlsSN",
        "outputId": "5e860cf0-0437-4b70-c1ae-52e0042f6f71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8894 - loss: 0.3793 - val_accuracy: 0.9655 - val_loss: 0.1126\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9711 - loss: 0.0919 - val_accuracy: 0.9737 - val_loss: 0.0867\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0563 - val_accuracy: 0.9755 - val_loss: 0.0804\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0412 - val_accuracy: 0.9797 - val_loss: 0.0796\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0314 - val_accuracy: 0.9780 - val_loss: 0.0818\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0264 - val_accuracy: 0.9730 - val_loss: 0.1071\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0223 - val_accuracy: 0.9778 - val_loss: 0.1014\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0212 - val_accuracy: 0.9780 - val_loss: 0.0940\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.9750 - val_loss: 0.1080\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0161 - val_accuracy: 0.9815 - val_loss: 0.0850\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.1010\n",
            "Akurasi pada data uji: 0.9799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambah 1 Hidden Layer Lagi (3 hidden layers)"
      ],
      "metadata": {
        "id": "9iMq9OcOl0Uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KzqLe_5l2Qn",
        "outputId": "206552db-d4ce-473a-cca0-3bf056625013"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.4007 - val_accuracy: 0.9687 - val_loss: 0.1027\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.0998 - val_accuracy: 0.9700 - val_loss: 0.0944\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.0630 - val_accuracy: 0.9777 - val_loss: 0.0726\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0449 - val_accuracy: 0.9797 - val_loss: 0.0717\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9885 - loss: 0.0371 - val_accuracy: 0.9810 - val_loss: 0.0740\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0306 - val_accuracy: 0.9810 - val_loss: 0.0747\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0264 - val_accuracy: 0.9807 - val_loss: 0.0746\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0198 - val_accuracy: 0.9788 - val_loss: 0.0836\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0226 - val_accuracy: 0.9790 - val_loss: 0.0910\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0162 - val_accuracy: 0.9752 - val_loss: 0.1211\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1737\n",
            "Akurasi pada data uji: 0.9709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perbandingan Akurasi dan Waktu Pelatihan\n",
        "\n",
        "Eksperimen dilakukan dengan tiga konfigurasi arsitektur jaringan saraf tiruan (JST) berbeda pada dataset MNIST. Tujuannya adalah membandingkan pengaruh jumlah neuron dan jumlah hidden layer terhadap akurasi serta waktu pelatihan."
      ],
      "metadata": {
        "id": "DDIdYiW2oEGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tabel Perbandingan\n",
        "\n",
        "\n",
        "| Model  | Konfigurasi Hidden Layer | Total Waktu Training (10 epoch) | Akurasi Test |\n",
        "| ------ | ------------------------ | ------------------------------- | ------------ |\n",
        "| **M1** | 128 → 64                 | ~80–85 detik                    | **0.9786**   |\n",
        "| **M2** | 256 → 128                | ~100–110 detik                  | **0.9799**   |\n",
        "| **M3** | 256 → 128 → 64           | ~100–120 detik                  | **0.9709**   |\n"
      ],
      "metadata": {
        "id": "DUpIS6yAnzNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Konfigurasi Dasar (128 → 64)\n",
        "\n",
        "Model pertama menggunakan dua hidden layer dengan jumlah neuron 128 dan 64.\n",
        "\n",
        "- Total waktu pelatihan: ± 80–85 detik\n",
        "\n",
        "- Akurasi data uji: 0.9786\n",
        "\n",
        "Model ini memiliki waktu pelatihan tercepat dan akurasinya cukup tinggi, sehingga dapat dianggap sebagai konfigurasi yang efisien."
      ],
      "metadata": {
        "id": "l0fgTcFRoVF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Hidden Layer Lebih Besar (256 → 128)\n",
        "\n",
        "Model kedua meningkatkan jumlah neuron pada kedua hidden layer menjadi 256 dan 128.\n",
        "\n",
        "- Total waktu pelatihan: ± 100–110 detik\n",
        "\n",
        "- Akurasi data uji: 0.9799\n",
        "\n",
        "Model ini menghasilkan akurasi tertinggi dibandingkan konfigurasi lainnya. Waktu pelatihan sedikit lebih lama, tetapi peningkatan akurasi cukup signifikan."
      ],
      "metadata": {
        "id": "ibZi-TLIoZ31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Penambahan Hidden Layer Baru (256 → 128 → 64)\n",
        "\n",
        "Model ketiga menambahkan satu hidden layer tambahan (64 neuron).\n",
        "\n",
        "- Total waktu pelatihan: ± 100–120 detik\n",
        "\n",
        "- Akurasi data uji: 0.9709\n",
        "\n",
        "Meskipun memiliki arsitektur paling kompleks, model ini justru menunjukkan penurunan akurasi pada data uji. Hal ini mengindikasikan terjadinya overfitting, di mana model terlalu menyesuaikan diri dengan data pelatihan dan kehilangan generalisasi."
      ],
      "metadata": {
        "id": "THAs5inaojcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kesimpulan\n",
        "\n",
        "Dari hasil pengujian, dapat disimpulkan bahwa:\n",
        "\n",
        "- Penambahan jumlah neuron meningkatkan akurasi tanpa memberikan lonjakan waktu pelatihan yang signifikan.\n",
        "\n",
        "- Penambahan hidden layer berlebih tidak selalu memberikan performa lebih baik, bahkan dapat menyebabkan overfitting sehingga akurasi menurun.\n",
        "\n",
        "- Hidden Layer Lebih Besar (256 → 128) merupakan konfigurasi paling optimal pada eksperimen ini, dengan keseimbangan terbaik antara akurasi dan waktu pelatihan."
      ],
      "metadata": {
        "id": "UzJxl-h0ovHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aktivasi Sigmoid (dibandingkan ReLU)"
      ],
      "metadata": {
        "id": "neQAGwULmAdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='sigmoid'),\n",
        "    Dense(128, activation='sigmoid'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7I_fTmEmBFv",
        "outputId": "216ace95-1ab6-4811-9d9f-ffb3af82eaae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8127 - loss: 0.7213 - val_accuracy: 0.9557 - val_loss: 0.1625\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9465 - loss: 0.1826 - val_accuracy: 0.9690 - val_loss: 0.1126\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.1193 - val_accuracy: 0.9732 - val_loss: 0.0886\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0790 - val_accuracy: 0.9755 - val_loss: 0.0825\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0599 - val_accuracy: 0.9765 - val_loss: 0.0775\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0449 - val_accuracy: 0.9797 - val_loss: 0.0689\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0322 - val_accuracy: 0.9798 - val_loss: 0.0683\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0241 - val_accuracy: 0.9812 - val_loss: 0.0681\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0187 - val_accuracy: 0.9788 - val_loss: 0.0694\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0136 - val_accuracy: 0.9792 - val_loss: 0.0845\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0865\n",
            "Akurasi pada data uji: 0.9790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perbandingan Fungsi Aktivasi: Sigmoid vs ReLU"
      ],
      "metadata": {
        "id": "H02kLPEXpMye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Hasil Pelatihan dengan Aktivasi ReLU\n",
        "\n",
        "- Akurasi pelatihan: 0.9943\n",
        "\n",
        "- Akurasi validasi: ± 0.9800\n",
        "\n",
        "- Akurasi data uji: 0.9786\n",
        "\n",
        "- Waktu pelatihan per epoch: ± 7–9 detik\n",
        "\n",
        "Model dengan ReLU sedikit lebih cepat dalam pelatihan dan stabil dalam menangani gradien. ReLU mencegah masalah vanishing gradient, sehingga pelatihan lebih efisien."
      ],
      "metadata": {
        "id": "s_ysBVC7pOpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Hasil Pelatihan dengan Aktivasi Sigmoid\n",
        "\n",
        "- Berdasarkan hasil training:\n",
        "\n",
        "- Akurasi pelatihan mencapai: 0.9961\n",
        "\n",
        "- Akurasi validasi terbaik: ± 0.9812\n",
        "\n",
        "- Akurasi data uji: 0.9790\n",
        "\n",
        "- Waktu pelatihan per epoch: ± 10–11 detik\n",
        "\n",
        "Model dengan Sigmoid menunjukkan performa yang baik, namun waktu pelatihannya lebih lama karena Sigmoid memiliki operasi eksponensial dan rentan mengalami vanishing gradient, terutama pada lapisan dalam."
      ],
      "metadata": {
        "id": "l0klSv5WpboY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ringkasan Perbandingan ReLU vs Sigmoid\n",
        "\n",
        "| Aspek                    | Sigmoid                            | ReLU                          |\n",
        "| ------------------------ | ---------------------------------- | ----------------------------- |\n",
        "| Akurasi Uji              | **0.9790**                         | 0.9786                        |\n",
        "| Kecepatan Pelatihan      | Lebih lambat (10–11 detik/epoch)   | Lebih cepat (7–9 detik/epoch) |\n",
        "| Stabilitas Gradien       | Rentan vanishing gradient          | Stabil dan efisien            |\n",
        "| Kompleksitas Perhitungan | Lebih tinggi (fungsi eksponensial) | Lebih rendah (max(0, x))      |\n",
        "| Cocok Untuk              | Model kecil, output probabilistik  | Deep learning modern          |\n"
      ],
      "metadata": {
        "id": "mYmGV-5gph9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kesimpulan\n",
        "\n",
        "- Sigmoid menghasilkan akurasi sedikit lebih tinggi daripada ReLU pada eksperimen ini, namun perbedaannya sangat kecil.\n",
        "\n",
        "- ReLU lebih cepat dilatih, karena operasinya sederhana dan tidak mengalami saturasi negatif.\n",
        "\n",
        "- Untuk model yang lebih besar atau lebih dalam, ReLU tetap lebih direkomendasikan karena menghindari vanishing gradient.\n",
        "\n",
        "- Pada kasus dataset MNIST dan arsitektur sederhana, kedua aktivasi memberikan performa hampir sama, sehingga pemilihan bergantung pada kecepatan pelatihan."
      ],
      "metadata": {
        "id": "-cowPfyEpn-f"
      }
    }
  ]
}