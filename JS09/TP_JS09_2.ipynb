{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeJjdzcSvsCnPWPTFZvXwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annisaeka123/2341720131_ML_2025/blob/main/JS09/TP_JS09_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TUGAS 2"
      ],
      "metadata": {
        "id": "6_5GqxCix_oY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
        "\n",
        "1. Menggunakan data spam.csv\n",
        "\n",
        "2. Fitur CountVectorizer dengan mengaktifkan stop_words\n",
        "\n",
        "3. Evaluasi hasilnya"
      ],
      "metadata": {
        "id": "LeFB-_q9yGhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\n",
        "\n",
        "1. Menggunakan data spam.csv\n",
        "\n",
        "2. Fitur TF-IDF dengan mengaktifkan stop_words\n",
        "\n",
        "3. Evaluasi hasilnya dan bandingkan dengan hasil pada Tugas no 2.\n",
        "\n",
        "4. Berikan kesimpulan fitur mana yang terbaik pada kasus data spam.csv"
      ],
      "metadata": {
        "id": "9RacasqByKJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Library dan Load Dataset"
      ],
      "metadata": {
        "id": "CK8ZSGER1LJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n",
        "# Hapus kolom tidak relevan\n",
        "df = df.drop(df.iloc[:, 2:], axis=1)\n",
        "df = df.rename(columns={'v1': 'label', 'v2': 'message'})\n",
        "\n",
        "# Encode label: spam=1, ham=0\n",
        "df['label'] = df['label'].str.strip().str.lower().map({'spam': 1, 'ham': 0})\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "oiZ-_krbyDZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MultinomialNB dengan CountVectorizer (stop_words='english')"
      ],
      "metadata": {
        "id": "CYP7ueeM1Vfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer\n",
        "cv = CountVectorizer(stop_words='english')\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)\n",
        "\n",
        "# Model Naive Bayes\n",
        "mnb_cv = MultinomialNB()\n",
        "mnb_cv.fit(X_train_cv, y_train)\n",
        "\n",
        "# Prediksi dan evaluasi\n",
        "y_pred_cv = mnb_cv.predict(X_test_cv)\n",
        "acc_cv = accuracy_score(y_test, y_pred_cv)\n",
        "\n",
        "print(\"=== MultinomialNB + CountVectorizer ===\")\n",
        "print(f\"Akurasi: {acc_cv:.4f}\")\n",
        "print(classification_report(y_test, y_pred_cv))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i1eviWB1V5K",
        "outputId": "659cab0e-5022-441b-f648-9a2def693c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MultinomialNB + CountVectorizer ===\n",
            "Akurasi: 0.9839\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       965\n",
            "           1       0.96      0.92      0.94       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.97      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MultinomialNB dengan TF-IDF (stop_words='english')"
      ],
      "metadata": {
        "id": "QraMFUJ11YWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Model Naive Bayes\n",
        "mnb_tfidf = MultinomialNB()\n",
        "mnb_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prediksi dan evaluasi\n",
        "y_pred_tfidf = mnb_tfidf.predict(X_test_tfidf)\n",
        "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "\n",
        "print(\"\\n=== MultinomialNB + TF-IDF ===\")\n",
        "print(f\"Akurasi: {acc_tfidf:.4f}\")\n",
        "print(classification_report(y_test, y_pred_tfidf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6meUGMA1ZDB",
        "outputId": "3f88298d-80af-435a-d2b8-20eeac38d3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MultinomialNB + TF-IDF ===\n",
            "Akurasi: 0.9668\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.75      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi dan Perbandingan Hasil"
      ],
      "metadata": {
        "id": "K85FEY7B1cUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil pengujian, model Multinomial Naive Bayes dengan CountVectorizer menghasilkan akurasi sebesar 98.39%, sedangkan model dengan TF-IDF menghasilkan akurasi sedikit lebih rendah yaitu 96.68%. Model dengan CountVectorizer juga menunjukkan nilai recall dan f1-score yang lebih seimbang antara kelas spam dan ham, dengan f1-score masing-masing sebesar 0.99 untuk kelas ham dan 0.94 untuk kelas spam. Sementara itu, model TF-IDF menunjukkan performa sangat baik pada kelas ham (recall 1.00) namun relatif lebih rendah pada kelas spam (recall 0.75), yang berarti beberapa pesan spam masih salah diklasifikasikan sebagai ham.\n",
        "\n",
        "Perbedaan performa ini terjadi karena CountVectorizer hanya menghitung frekuensi kemunculan kata tanpa mempertimbangkan bobot relatif antar dokumen, sehingga cocok untuk dataset spam.csv yang sederhana dan memiliki pola kata spam yang sering berulang. Sebaliknya, TF-IDF memberikan bobot lebih tinggi pada kata-kata unik dan menurunkan bobot kata umum, sehingga lebih cocok untuk dataset teks yang lebih kompleks dan beragam. Dalam kasus ini, karena banyak kata spam muncul berulang dengan pola serupa, CountVectorizer dapat mengenali pola tersebut dengan lebih baik sehingga memberikan akurasi yang lebih tinggi."
      ],
      "metadata": {
        "id": "EQ9sw4z12MNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kesimpulan"
      ],
      "metadata": {
        "id": "tNtpEsK-1c-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari hasil evaluasi dan perbandingan, dapat disimpulkan bahwa fitur terbaik untuk kasus klasifikasi pesan spam pada dataset spam.csv adalah CountVectorizer dengan stop_words aktif. Fitur ini memberikan performa yang lebih stabil dan akurasi lebih tinggi dibandingkan TF-IDF pada dataset dengan pola kata yang berulang dan sederhana. Namun, untuk dataset teks yang lebih kompleks atau dengan variasi kata yang tinggi, TF-IDF tetap menjadi pilihan yang lebih unggul karena mampu menonjolkan kata-kata yang paling relevan terhadap kelas tertentu."
      ],
      "metadata": {
        "id": "rbTazfR02PN5"
      }
    }
  ]
}